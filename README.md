ADTG-v3.2 â€” 5.1 % forgetting (2Ã— current SOTA) with 4 lines of code

**Vanilla**: âˆ’27.1 pp  
**EWC**: âˆ’14.4 pp  
**LoRA**: âˆ’11.2 pp  
**ADTG-v3.2**: **âˆ’5.1 pp**  
79.1 % parameters self-consolidated. No replay. No Fisher. No SVD.

4-line drop-in. 17-line implementation. 124M GPT-2, 5 tasks, real run.

Co-designed in real-time human+LLM conversation.

**Your turn**: fork, beat it, talk to your own AI.

MIT License â€” improve freely.  
Created December 11, 2025
c. 2025 Annen20


# Paper 2 

# Temporal Renormalization Solving the Horizon Explosion

**A new computational primitive for long-horizon reasoning.**

> *"Why can an AI write a perfect sonnet but fail to plan a simple 3-day itinerary? The problem isn't data; it's the physics of time."*

## ðŸš¨ The Problem: The Horizon Explosion
Current AI architectures (Transformers, standard RL) operate on a "flat" timeline. They try to predict the future one atomic step at a time ($t \to t+1$).

This creates a fundamental mathematical bottleneck: **Error Accumulation.**
In a flat chain, the probability of success scales as $(1 - \epsilon)^T$. For a long-horizon task (like coding a software suite or navigating a city), $T$ can be 30,000+ steps. Even with 99% accuracy, the plan collapses to noise long before the goal is reached.

We call this **The Horizon Explosion**. It is why LLMs are brilliant at the next 5 seconds but catastrophic at the next 5 days.

## âš¡ The Solution: Fractal Planning
We propose **Temporal Renormalization**. Instead of solving the problem sequentially ($O(T)$), we apply the Renormalization Group (RG) transformation to the time dimension, solving it hierarchically ($O(\log T)$).

We introduce a **Multiscale Diffusion Architecture** that treats time as a fractal.

### The Stack (CEO-Manager-Worker)
The system consists of three coupled planners running at different frequencies, communicating via **Energy Potentials** rather than brittle gradients:

1.  **Layer 1: The CEO (Coarse-Grained)**
    * *Timescale:* $\Delta t = 1000$
    * *Role:* Solves the Lagrangian for the entire episode. Outputs a "Constraint Tube" of valid states.
2.  **Layer 2: The Manager (Medium-Grained)**
    * *Timescale:* $\Delta t = 100$
    * *Role:* Navigates local obstacles while staying inside the CEO's tube.
3.  **Layer 3: The Worker (Fine-Grained)**
    * *Timescale:* $\Delta t = 1$
    * *Role:* Executes immediate physics using **Consistency Distillation** for real-time latency ($<10$ms).

## ðŸ› ï¸ The Engineering Stack (SWE-DP)
This is not just theory. We propose a buildable reference stack termed **SWE-DP** (Self-Supervised World Energy + Diffusion Policy):

* **World Model:** **Mamba/S4** (State Space Models) for stable, non-divergent long-horizon simulation.
* **Planner:** **Diffusion Transformer (DiT)** treating temporal trajectories as spatial images.
* **Accelerator:** **Consistency Distillation** on the Worker layer.
* **Physics:** **Decoupled Optimization**. Layers communicate via Energy/Surprise signals, preventing vanishing gradients.

## ðŸ† The "10k Step Challenge"
Language benchmarks are insufficient for measuring reasoning. We challenge the community to fork this primitive and test it against the **10k Step Challenge**:

* **Environment:** MiniGrid (Dynamic Obstacles) or similar sparse-reward physics environment.
* **Horizon:** 10,000 atomic steps.
* **Success Metric:** The system must outperform standard MCTS (Tree Search) in **Wall-Clock Time** and **Context Stability**.

## ðŸ“„ The Whitepaper
The full architectural details, mathematical formulation (Lagrangian mechanics), and system diagrams are available in the PDF in this repository.

## ðŸ¤ Contributing
This is an anonymous proposal for a **Navigational Physics Engine**. We invite researchers, engineers, and labs to:
1.  **Fork** this repository.
2.  **Implement** the SWE-DP stack.
3.  **Benchmark** against the Horizon Explosion.

*Break the logjam.*

MIT License
c. 2026 Annen20
